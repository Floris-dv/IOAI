{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0cd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a63486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data\n",
    "def load_data() -> Tuple[Dataset, Dataset, Dataset]:\n",
    "    from torchvision import datasets\n",
    "    from torchvision.transforms import ToTensor\n",
    "\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"data\", train=True, download=True, transform=ToTensor()\n",
    "    )\n",
    "\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\", train=False, download=True, transform=ToTensor()\n",
    "    )\n",
    "\n",
    "    validation_size = int(0.6 * len(test_data))\n",
    "    test_size = len(test_data) - validation_size\n",
    "    validation_data, test_data = random_split(\n",
    "        test_data, [validation_size, test_size])\n",
    "    return training_data, validation_data, test_data\n",
    "\n",
    "\n",
    "training_data, validation_data, test_data = load_data()\n",
    "training_loader = DataLoader(training_data, batch_size=4, shuffle=True)\n",
    "# needs to be reproducible, so no shuffling\n",
    "validation_loader = DataLoader(validation_data, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278105fa",
   "metadata": {},
   "source": [
    "# Model architecture:\n",
    "```mermaid\n",
    "flowchart \n",
    "    A{Input: \\n2D 28x28 array} \n",
    "    A -->|28, 28| B[Flatten]\n",
    "    B -->|784| C[Linear + ReLU]\n",
    "    C -->|512| D[Linear + ReLU]\n",
    "    D -->|512| E[Linear]\n",
    "    E -->|10| F{Output: \\nprobabilities of\\neach label}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670d2671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Using cpu device\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the model\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "config = {}\n",
    "\n",
    "model = Model(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547be86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EPOCH 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 1000 loss: 1.3545449294298888\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 2000 loss: 0.7317184730656445\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 3000 loss: 0.6615200548283756\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 4000 loss: 0.5781671963580884\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 5000 loss: 0.5578867159232032\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 6000 loss: 0.5419525289270095\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 7000 loss: 0.5187083787210286\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 8000 loss: 0.4792804029965773\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 9000 loss: 0.4838538914558012\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 10000 loss: 0.4693503861064091\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 11000 loss: 0.462582439044374\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 12000 loss: 0.4676974238224793\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 13000 loss: 0.43523717983881943\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 14000 loss: 0.426569092213409\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 15000 loss: 0.4150264247608138\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LOSS train 0.4150264247608138 valid 0.4451819360256195\n",
       "EPOCH 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 1000 loss: 0.3998089502919465\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 2000 loss: 0.41008523176563905\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 3000 loss: 0.4033077511799056\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 4000 loss: 0.3955201131055364\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 5000 loss: 0.4093074310820084\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 6000 loss: 0.39660053290193903\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 7000 loss: 0.37872266429720913\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 8000 loss: 0.3795764488193672\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 9000 loss: 0.39418133225117347\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 10000 loss: 0.40835364494629905\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 11000 loss: 0.39210483338602353\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 12000 loss: 0.3859634173109371\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 13000 loss: 0.36857391634742814\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 14000 loss: 0.3992565610330785\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 15000 loss: 0.3720108799263544\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LOSS train 0.3720108799263544 valid 0.3879810869693756\n",
       "EPOCH 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 1000 loss: 0.3589565509983877\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 2000 loss: 0.37594136465271005\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 3000 loss: 0.3478714046175446\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 4000 loss: 0.35116436267009704\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 5000 loss: 0.3498368435918237\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 6000 loss: 0.3458454228466726\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 7000 loss: 0.35142021947255125\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 8000 loss: 0.36657327230589\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 9000 loss: 0.3566670378212584\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 10000 loss: 0.33185284006212895\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 11000 loss: 0.34707213478761695\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 12000 loss: 0.32892330991991914\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 13000 loss: 0.34242258520697944\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 14000 loss: 0.352343448432337\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 15000 loss: 0.3551879076836849\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LOSS train 0.3551879076836849 valid 0.4083085060119629\n",
       "EPOCH 9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 1000 loss: 0.3293057084519532\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 2000 loss: 0.3232165395982738\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 3000 loss: 0.3297821080376743\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 4000 loss: 0.3323437011573842\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 5000 loss: 0.32138048060561414\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 6000 loss: 0.3422932093202253\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 7000 loss: 0.31971878160431516\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 8000 loss: 0.3043320016366488\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 9000 loss: 0.33493755099902045\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 10000 loss: 0.327584721623949\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 11000 loss: 0.3405358667632408\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 12000 loss: 0.30782074210689464\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 13000 loss: 0.3126215653450781\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 14000 loss: 0.31839185775439544\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 15000 loss: 0.31149232537587523\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LOSS train 0.31149232537587523 valid 0.3739641010761261\n",
       "EPOCH 10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 1000 loss: 0.30649648767196774\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 2000 loss: 0.3260837357753189\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 3000 loss: 0.30214775839423236\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 4000 loss: 0.292137747337194\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 5000 loss: 0.32010161901660467\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 6000 loss: 0.2933321541266778\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 7000 loss: 0.2955069772548286\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 8000 loss: 0.3197626822444727\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 9000 loss: 0.32605947726782325\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 10000 loss: 0.309505619931675\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 11000 loss: 0.28475356966631216\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 12000 loss: 0.2920735901299649\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 13000 loss: 0.29579464676836503\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 14000 loss: 0.29988778893547713\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  batch 15000 loss: 0.3047588032895583\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LOSS train 0.3047588032895583 valid 0.3930676579475403\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "def train_one_epoch(tb_writer=None, epoch_index=0):\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000  # loss per batch\n",
    "            print(\"  batch {} loss: {}\".format(i + 1, last_loss))\n",
    "            if tb_writer is not None:\n",
    "                tb_writer.add_scalar('Training loss', running_loss /\n",
    "                                     1000, epoch_index * len(training_loader) + i)\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "    return last_loss\n",
    "\n",
    "\n",
    "start_timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "writer = SummaryWriter(f'runs/testing_{start_timestamp}')\n",
    "\n",
    "EPOCHS = 5\n",
    "best_validation_loss = 1e9\n",
    "\n",
    "for epoch in range(EPOCHS, 2*EPOCHS):\n",
    "    print(f\"EPOCH {epoch + 1}\")\n",
    "\n",
    "    # Train the model\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(writer, epoch)\n",
    "\n",
    "    running_validation_loss = 0.0\n",
    "\n",
    "    # Test it's intermediate performance\n",
    "    model.eval()\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_validation_loss += vloss\n",
    "    avg_vloss = running_validation_loss / (i + 1)\n",
    "    print(\"LOSS train {} valid {}\".format(avg_loss, avg_vloss))\n",
    "    writer.add_scalars('Training vs. Validation loss', {\n",
    "                       'Training': avg_loss, 'Validation': avg_vloss}, epoch + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    if avg_vloss < best_validation_loss:\n",
    "        best_validation_loss = avg_vloss\n",
    "        model_path = f\"model_{start_timestamp}_{epoch}\"\n",
    "        torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "C:\\Users\\flori\\AppData\\Local\\Programs\\Python\\Python310\\share\\jupyter\\kernels\\python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
